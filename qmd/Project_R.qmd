---
title: "Analyse statistique des usages des r√©seaux sociaux et de leurs effets √©motionnels"
date: "2025-12-25"
format:
  live-html:
    theme: cosmo
    toc: true
resources:
  - data
webr:
  packages: ["readr", "dplyr", "janitor"]
---


## Introduction : Une crise silencieuse

Les r√©seaux sociaux ont transform√© nos vies en moins d'une d√©cennie. 
Aujourd'hui, 4,9 milliards d'utilisateurs passent en moyenne 2h30 par jour 
sur ces plateformes. Mais √† quel prix pour notre sant√© mentale ?

**Le paradoxe de l'hyperconnexion :** Cens√©s nous rapprocher, ces outils 
g√©n√®rent anxi√©t√©, comparaison sociale et addiction num√©rique.

**Notre mission :** Quantifier l'impact psychologique de l'usage des r√©seaux 
sociaux et identifier les profils √† risque pour mieux pr√©venir.


## √âtape 1 : Acquisition et pr√©traitement des donn√©es

### 1.1 Description Dataset


```{webr}
library(readr)
library(dplyr)
library(tidyr)

# Lire les donn√©es brutes
data_raw <- read_csv("data/train.csv",
  show_col_types = FALSE,
  na = c("", "NA", "NULL")
)
glimpse(data_raw)
cat("   - Nombre de lignes :", nrow(data_raw), "\n")
cat("   - Nombre de colonnes :", ncol(data_raw), "\n")
print(summary(data_raw))

```
Une exploration initiale du dataset a √©t√© r√©alis√©e √† l‚Äôaide des fonctions glimpse() et summary(), permettant d‚Äôidentifier la structure des donn√©es, les types des variables, la taille du dataset ainsi que les principales statistiques descriptives. Cette √©tape permet de v√©rifier la coh√©rence des donn√©es avant toute analyse approfondie.



### 1.2 Correction des anomalies de format


```{webr-r}
#| echo: true
#| warning: false
#| message: false
#| label: correct-data

# Correction des donn√©es m√©lang√©es (colonnes Age et Gender parfois invers√©es)
data_clean <- data_raw %>%
  mutate(
    # D√©tection des lignes o√π Age n'est pas num√©rique
    age_numeric = suppressWarnings(as.numeric(Age)),
    gender_char = as.character(Gender),
    
    # Correction des inversions Age/Gender
    age_corrected = ifelse(is.na(age_numeric), as.numeric(gender_char), age_numeric),
    gender_corrected = ifelse(is.na(age_numeric), Age, gender_char),
    
    # D√©tection des cas o√π Gender est num√©rique (c'est probablement Age)
    gender_is_numeric = suppressWarnings(!is.na(as.numeric(Gender))),
    
    # √âchange final des valeurs
    age_final = ifelse(gender_is_numeric, as.numeric(Gender), age_corrected),
    gender_final = ifelse(gender_is_numeric, Age, gender_corrected),
    
    # Standardisation des cat√©gories de genre
    gender_final = case_when(
      tolower(gender_final) %in% c("male", "m", "homme") ~ "Male",
      tolower(gender_final) %in% c("female", "f", "femme") ~ "Female",
      tolower(gender_final) %in% c("non-binary", "nonbinary", "nb") ~ "Non-binary",
      TRUE ~ as.character(gender_final)
    )
  ) %>%
  # S√©lection et renommage des colonnes finales
  select(
    user_id = User_ID,
    age = age_final,
    gender = gender_final,
    platform = Platform,
    daily_usage_time_minutes = `Daily_Usage_Time (minutes)`,
    posts_per_day = Posts_Per_Day,
    likes_received_per_day = Likes_Received_Per_Day,
    comments_received_per_day = Comments_Received_Per_Day,
    messages_sent_per_day = Messages_Sent_Per_Day,
    dominant_emotion = Dominant_Emotion
  )
cat("   Variables finales:", paste(names(data_clean), collapse = ", "), "\n")
```
Interpr√©tation : Cette √©tape cruciale corrige les anomalies structurelles dans les donn√©es. Les inversions occasionnelles entre les colonnes Age et Gender sont d√©tect√©es et corrig√©es automatiquement. La standardisation des cat√©gories de genre assure la coh√©rence des analyses d√©mographiques. Cette robustesse face aux erreurs de saisie garantit la fiabilit√© des analyses ult√©rieures.




## √âtape 2 : Nettoyage et validation

### 2.1 Validation et filtrage des donn√©es
```{webr-r}
#| echo: true
#| warning: false
#| message: false
#| label: clean-data

cat("üìä Dimensions initiales du dataset nettoy√©:\n")
print(dim(data_clean))

# Analyse des valeurs manquantes
cat("\nüîç Analyse des valeurs manquantes par colonne:\n")
missing_summary <- colSums(is.na(data_clean))
print(missing_summary)

# Nettoyage final des donn√©es
data <- data_clean %>%
  # Conversion des types de donn√©es
  mutate(
    age = as.numeric(age),
    gender = factor(gender, levels = c("Male", "Female", "Non-binary")),
    platform = factor(platform),
    dominant_emotion = factor(dominant_emotion)
  ) %>%
  # Suppression des valeurs manquantes critiques
  filter(
    !is.na(age),
    !is.na(daily_usage_time_minutes),
    !is.na(gender),
    !is.na(dominant_emotion)
  ) %>%
  # Filtrage des valeurs aberrantes
  filter(
    age >= 18 & age <= 70,                    # √Çge r√©aliste
    daily_usage_time_minutes >= 10 & daily_usage_time_minutes <= 480  # Usage r√©aliste (8h max)
  )

cat("\n‚úÖ Donn√©es finales apr√®s nettoyage:\n")
cat("   - Observations finales:", nrow(data), "\n")
cat("   - Variables:", ncol(data), "\n")
cat("   - Observations exclues:", nrow(data_clean) - nrow(data), "\n")

```
Interpr√©tation : Cette phase de validation garantit la qualit√© des donn√©es d'entr√©e. Le filtrage des valeurs aberrantes (√¢ges non r√©alistes, temps d'usage extr√™mes) √©limine les observations qui pourraient biaiser les analyses. La conversion des types de donn√©es assure la coh√©rence des op√©rations statistiques. La r√©duction du dataset refl√®te un nettoyage rigoureux plut√¥t qu'une perte d'information significative.



###  2.2 Cr√©ation de variables analytiques



```{webr-r}
#| echo: true
#| warning: false
#| message: false
#| label: create-variables

data <- data %>%
  mutate(
    # Cat√©gorisation du temps d'usage
    usage_level = case_when(
      daily_usage_time_minutes < 60 ~ "Faible (<1h)",
      daily_usage_time_minutes < 120 ~ "Mod√©r√© (1-2h)",
      daily_usage_time_minutes < 180 ~ "√âlev√© (2-3h)",
      TRUE ~ "Tr√®s √©lev√© (>3h)"
    ),
    usage_level = factor(
      usage_level,
      levels = c("Faible (<1h)", "Mod√©r√© (1-2h)", "√âlev√© (2-3h)", "Tr√®s √©lev√© (>3h)")
    ),
    
    # Segmentation par √¢ge
    age_group = cut(
      age,
      breaks = c(18, 25, 30, 35, 70),
      labels = c("18-25", "26-30", "31-35", "36+"),
      include.lowest = TRUE
    ),
    
    # Score d'engagement composite
    engagement_score = posts_per_day + 
      (likes_received_per_day / 10) + 
      (comments_received_per_day / 5) + 
      (messages_sent_per_day / 20),
    
    # Variables binaires pour l'analyse
    anxiety_binary = ifelse(dominant_emotion == "Anxiety", 1, 0),
    negative_emotion = ifelse(dominant_emotion %in% c("Anxiety", "Sadness", "Anger"), 1, 0),
    positive_emotion = ifelse(dominant_emotion %in% c("Happiness"), 1, 0),
    
    # Ratios d'interaction
    interaction_ratio = ifelse(posts_per_day > 0, 
                              (likes_received_per_day + comments_received_per_day) / posts_per_day, 
                              0),
    
    # Intensit√© d'usage (minutes par publication)
    usage_intensity = ifelse(posts_per_day > 0, 
                            daily_usage_time_minutes / posts_per_day, 
                            daily_usage_time_minutes)
  )

```
Interpr√©tation : La cr√©ation de variables d√©riv√©es enrichit consid√©rablement l'analyse. Le score d'engagement composite permet une √©valuation multidimensionnelle de l'activit√© en ligne. La cat√©gorisation de l'usage facilite les analyses comparatives. La variable anxiety_binary sert de cible pour les mod√®les pr√©dictifs. Ces transformations pr√©parent le terrain pour des analyses sophistiqu√©es tout en restant interpr√©tables.


## √âtape 3 : Analyse descriptive
### 3.1 Statistiques descriptives fondamentales

```{webr-r}
#| echo: true
#| warning: false
#| message: false
#| label: descriptive-stats

library(psych)


cat("ANALYSE DESCRIPTIVE COMPL√àTE\n")

# Statistiques de base des variables continues
cat(" 1. STATISTIQUES DESCRIPTIVES DES VARIABLES CONTINUES:\n")
describe_stats <- describe(
  select(
    data,
    age,
    daily_usage_time_minutes,
    posts_per_day,
    likes_received_per_day,
    comments_received_per_day,
    messages_sent_per_day,
    engagement_score
  )
)
print(describe_stats)

# Distribution d√©mographique
cat("\nüë• 2. DISTRIBUTION D√âMOGRAPHIQUE PAR GENRE:\n")
gender_dist <- data %>%
  count(gender) %>%
  mutate(
    percentage = n / sum(n) * 100,
    cumulative = cumsum(percentage)
  )
print(gender_dist)

# Distribution des plateformes
cat("\nüì± 3. DISTRIBUTION PAR PLATEFORME SOCIALE:\n")
platform_dist <- data %>%
  count(platform) %>%
  arrange(desc(n)) %>%
  mutate(
    percentage = n / sum(n) * 100,
    rank = row_number()
  )
print(platform_dist)

# Distribution des √©motions
cat("\nüòä 4. DISTRIBUTION DES √âMOTIONS DOMINANTES:\n")
emotion_dist <- data %>%
  count(dominant_emotion) %>%
  arrange(desc(n)) %>%
  mutate(
    percentage = n / sum(n) * 100,
    emotion_type = ifelse(dominant_emotion == "Happiness", "Positive",
                         ifelse(dominant_emotion %in% c("Neutral", "Boredom"), "Neutre", "N√©gative"))
  )
print(emotion_dist)

# Synth√®se des distributions
cat("\nüìä SYNTH√àSE DES DISTRIBUTIONS:\n")
cat("   - Effectif total analys√©:", nrow(data), "observations\n")
cat("   - √Çge moyen:", round(mean(data$age), 1), "ans\n")
cat("   - Usage moyen:", round(mean(data$daily_usage_time_minutes), 1), "minutes/jour\n")
cat("   - Taux d'anxi√©t√© global:", round(mean(data$anxiety_binary) * 100, 1), "%\n")
```



### 3.2 Analyse des corr√©lations


```{webr-r}
#| echo: true
#| echo: true
#| warning: false
#| message: false
#| label: correlation-analysis

library(corrplot)

cat("\nüîó 5. MATRICE DE CORR√âLATION ENTRE VARIABLES CL√âS:\n")

# Calcul de la matrice de corr√©lation
cor_matrix <- cor(
  select(data,
         daily_usage_time_minutes,
         posts_per_day,
         likes_received_per_day,
         comments_received_per_day,
         messages_sent_per_day,
         engagement_score,
         anxiety_binary
  ),
  use = "complete.obs"
)

print(round(cor_matrix, 3))

# Identification des corr√©lations significatives
cat("\nüéØ CORR√âLATIONS SIGNIFICATIVES (|r| > 0.3):\n")
cor_df <- as.data.frame(as.table(cor_matrix))
names(cor_df) <- c("Var1", "Var2", "Correlation")

significant_cors <- cor_df %>%
  filter(Var1 != Var2 & abs(Correlation) > 0.3) %>%
  arrange(desc(abs(Correlation)))

if(nrow(significant_cors) > 0) {
  print(significant_cors)
} else {
  cat("Aucune corr√©lation forte d√©tect√©e (|r| > 0.3)\n")
}

# Corr√©lation sp√©cifique avec l'anxi√©t√©
cat("\nüò∞ CORR√âLATION AVEC L'ANXI√âT√â:\n")
anxiety_correlations <- cor_df %>%
  filter(Var2 == "anxiety_binary" & Var1 != "anxiety_binary") %>%
  arrange(desc(abs(Correlation)))

print(anxiety_correlations)

```
Interpr√©tation : La matrice de corr√©lation r√©v√®le des relations structurelles importantes. La corr√©lation positive entre le temps d'usage et l'anxi√©t√© confirme l'hypoth√®se principale. Les fortes corr√©lations entre les diff√©rentes mesures d'engagement sugg√®rent des comportements coh√©rents. L'absence de corr√©lation forte avec certaines variables peut indiquer des dimensions ind√©pendantes du ph√©nom√®ne √©tudi√©.


## √âtape 4 : Visualisations analytiques
### 4.1 Analyse exploratoire des distributions

```{webr-r}
#| echo: true
#| warning: false
#| message: false
#| label: distribution-plots
#| fig-width: 10
#| fig-height: 6

library(ggplot2)
library(gridExtra)

# Configuration du th√®me
theme_set(theme_minimal(base_size = 12))
theme_update(
  plot.title = element_text(hjust = 0.5, face = "bold", size = 14),
  plot.subtitle = element_text(hjust = 0.5, size = 10, color = "gray50"),
  axis.title = element_text(face = "bold"),
  legend.title = element_text(face = "bold")
)

# Distribution du temps d'utilisation
p1 <- ggplot(data, aes(x = daily_usage_time_minutes)) +
  geom_histogram(aes(y = ..density..), bins = 30, 
                 fill = "#4E79A7", alpha = 0.7, color = "white") +
  geom_density(color = "#2E5984", linewidth = 1.2, alpha = 0.5) +
  geom_vline(aes(xintercept = mean(daily_usage_time_minutes)),
             color = "#E15759", linetype = "dashed", linewidth = 1) +
  geom_vline(aes(xintercept = median(daily_usage_time_minutes)),
             color = "#59A14F", linetype = "dashed", linewidth = 1) +
  annotate("text", x = mean(data$daily_usage_time_minutes), y = 0.015,
           label = paste("Moyenne =", round(mean(data$daily_usage_time_minutes), 1)),
           color = "#E15759", hjust = -0.1) +
  annotate("text", x = median(data$daily_usage_time_minutes), y = 0.013,
           label = paste("M√©diane =", round(median(data$daily_usage_time_minutes), 1)),
           color = "#59A14F", hjust = -0.1) +
  labs(
    title = "Distribution du temps d'utilisation quotidien",
    subtitle = "Analyse de la variable principale: minutes par jour",
    x = "Temps d'utilisation (minutes/jour)",
    y = "Densit√© de probabilit√©",
    caption = paste("N =", nrow(data), "observations | SD =", 
                   round(sd(data$daily_usage_time_minutes), 1))
  ) +
  theme(plot.title = element_text(hjust = 0.5))

# Distribution des √¢ges
p2 <- ggplot(data, aes(x = age)) +
  geom_histogram(aes(y = ..density..), bins = 20, 
                 fill = "#F28E2B", alpha = 0.7, color = "white") +
  geom_density(color = "#B07AA1", linewidth = 1.2, alpha = 0.5) +
  labs(
    title = "Distribution des √¢ges des utilisateurs",
    subtitle = "Analyse d√©mographique de l'√©chantillon",
    x = "√Çge (ann√©es)",
    y = "Densit√© de probabilit√©",
    caption = paste("Moyenne =", round(mean(data$age), 1), "ans | M√©diane =", median(data$age))
  ) +
  theme(plot.title = element_text(hjust = 0.5))

# Combinaison des graphiques
grid.arrange(p1, p2, ncol = 2)

```


###  4.2 Analyse comparative par genre et √¢ge

```{webr-r}
#| echo: true
#| warning: false
#| message: false
#| label: comparative-analysis
#| fig-width: 10
#| fig-height: 6

# Temps d'utilisation par genre
gender_stats <- data %>%
  group_by(gender) %>%
  summarise(
    moyenne = mean(daily_usage_time_minutes),
    mediane = median(daily_usage_time_minutes),
    sd = sd(daily_usage_time_minutes),
    n = n(),
    .groups = "drop"
  ) %>%
  mutate(
    pourcentage = n / sum(n) * 100,
    label = paste0(round(moyenne, 1), " min\n(n=", n, ")")
  )

p3 <- ggplot(data, aes(x = gender, y = daily_usage_time_minutes, fill = gender)) +
  geom_boxplot(alpha = 0.7, outlier.color = "red", outlier.shape = 1) +
  geom_jitter(width = 0.2, alpha = 0.3, size = 1, color = "gray40") +
  geom_point(data = gender_stats, aes(x = gender, y = moyenne), 
             shape = 23, size = 4, fill = "yellow", color = "black") +
  geom_text(data = gender_stats, aes(x = gender, y = max(data$daily_usage_time_minutes) * 0.95, 
                                     label = label),
            size = 3.5, fontface = "bold") +
  labs(
    title = "Comparaison du temps d'utilisation par genre",
    subtitle = "Boxplot avec points individuels et moyenne (losange)",
    x = "Genre",
    y = "Temps d'utilisation (minutes/jour)",
    fill = "Genre",
    caption = paste("Test ANOVA p-value =", 
                   round(summary(aov(daily_usage_time_minutes ~ gender, data = data))[[1]]$`Pr(>F)`[1], 4))
  ) +
  scale_fill_manual(values = c("Male" = "#4E79A7", "Female" = "#F28E2B", "Non-binary" = "#59A14F")) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 14),
    legend.position = "none",
    panel.grid.major.x = element_blank()
  )

# Temps d'utilisation par groupe d'√¢ge
age_group_stats <- data %>%
  group_by(age_group) %>%
  summarise(
    moyenne = mean(daily_usage_time_minutes),
    mediane = median(daily_usage_time_minutes),
    sd = sd(daily_usage_time_minutes),
    n = n(),
    .groups = "drop"
  ) %>%
  mutate(
    pourcentage = n / sum(n) * 100,
    label = paste0(round(moyenne, 1), " min")
  )

p4 <- ggplot(data, aes(x = age_group, y = daily_usage_time_minutes, fill = age_group)) +
  geom_violin(alpha = 0.6, trim = FALSE) +
  geom_boxplot(width = 0.2, alpha = 0.8, outlier.shape = NA) +
  geom_point(data = age_group_stats, aes(x = age_group, y = moyenne),
             shape = 18, size = 4, color = "red") +
  geom_text(data = age_group_stats, aes(x = age_group, y = moyenne, label = label),
            vjust = -1.5, size = 4, fontface = "bold") +
  labs(
    title = "Temps d'utilisation selon les groupes d'√¢ge",
    subtitle = "Violin plot montrant la densit√© et boxplot superpos√©",
    x = "Groupe d'√¢ge",
    y = "Temps d'utilisation (minutes/jour)",
    fill = "Groupe d'√¢ge",
    caption = "Point rouge = moyenne | Largeur = densit√© de distribution"
  ) +
  scale_fill_brewer(palette = "Set2") +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 14),
    legend.position = "none",
    panel.grid.major.x = element_blank()
  )

grid.arrange(p3, p4, ncol = 2)
```

###  4.3 Analyse des plateformes et √©motions


```{webr-r}
#| echo: true
#| warning: false
#| message: false
#| label: platform-emotion-analysis
#| fig-width: 12
#| fig-height: 8

# Analyse comparative des plateformes
platform_stats <- data %>%
  group_by(platform) %>%
  summarise(
    avg_usage = mean(daily_usage_time_minutes),
    avg_posts = mean(posts_per_day),
    n = n(),
    .groups = "drop"
  ) %>%
  mutate(
    pourcentage = n / sum(n) * 100,
    platform_label = paste0(platform, "\n(n=", n, ")")
  ) %>%
  arrange(desc(avg_usage))

p5 <- ggplot(platform_stats, aes(x = reorder(platform_label, avg_usage), y = avg_usage)) +
  geom_bar(stat = "identity", aes(fill = avg_usage), alpha = 0.8) +
  geom_text(aes(label = paste0(round(avg_usage, 1), " min")), 
            hjust = -0.1, size = 3.5, fontface = "bold") +
  geom_text(aes(y = 0, label = paste0(round(pourcentage, 1), "%")), 
            hjust = 1.1, size = 3, color = "white", fontface = "bold") +
  coord_flip(ylim = c(0, max(platform_stats$avg_usage) * 1.15)) +
  labs(
    title = "Temps d'utilisation moyen par plateforme sociale",
    subtitle = "Classement des plateformes par engagement temporel",
    x = "Plateforme (avec effectif)",
    y = "Temps moyen d'utilisation (minutes/jour)",
    fill = "Minutes\nmoyennes",
    caption = "Pourcentage en blanc = part des utilisateurs"
  ) +
  scale_fill_gradient(low = "#76B7B2", high = "#E15759", name = "Intensit√©") +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 14),
    legend.position = "right",
    panel.grid.major.y = element_blank()
  )

# Heatmap plateforme √ó √©motion
platform_emotion_matrix <- data %>%
  count(platform, dominant_emotion) %>%
  group_by(platform) %>%
  mutate(
    total_platform = sum(n),
    proportion = n / total_platform * 100
  ) %>%
  ungroup()

p6 <- ggplot(platform_emotion_matrix, 
              aes(x = platform, y = dominant_emotion, fill = proportion)) +
  geom_tile(color = "white", size = 0.8) +
  geom_text(aes(label = paste0(round(proportion, 0), "%\n(n=", n, ")")),
            color = "white", size = 3, fontface = "bold") +
  scale_fill_gradient(
    low = "#EDF8FB", 
    high = "#2CA25F",
    name = "Pourcentage\npar plateforme",
    limits = c(0, 50)
  ) +
  labs(
    title = "Heatmap: Distribution des √©motions par plateforme",
    subtitle = "Pourcentage d'utilisateurs par √©motion pour chaque plateforme",
    x = "Plateforme sociale",
    y = "√âmotion dominante",
    caption = "Lecture: % d'utilisateurs de chaque plateforme ayant cette √©motion"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 14),
    axis.text.x = element_text(angle = 45, hjust = 1),
    panel.grid = element_blank(),
    legend.position = "right"
  ) +
  coord_fixed(ratio = 1)

grid.arrange(p5, p6, ncol = 2)
```


###  4.4 Relation usage-anxi√©t√©

```{webr-r}
# Assurer que anxiety_binary existe
data <- data %>%
  mutate(anxiety_binary = ifelse(dominant_emotion == "Anxiety", 1, 0))

# Taux d'anxi√©t√© par niveau d'usage
anxiety_by_usage <- data %>%
  group_by(usage_level) %>%
  summarise(
    anxiety_rate = mean(anxiety_binary) * 100,
    n = n(),
    se = sd(anxiety_binary) / sqrt(n) * 100,
    .groups = "drop"
  ) %>%
  mutate(
    ci_lower = anxiety_rate - 1.96 * se,
    ci_upper = anxiety_rate + 1.96 * se
  )

# Graphique 7 (identique √† votre code original)
p7 <- ggplot(anxiety_by_usage, aes(x = usage_level, y = anxiety_rate, group = 1)) +
  geom_line(color = "#E15759", linewidth = 1.5, alpha = 0.7) +
  geom_point(size = 5, color = "#E15759", fill = "white", shape = 21, stroke = 2) +
  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), 
                width = 0.2, color = "#E15759", linewidth = 1, alpha = 0.5) +
  geom_text(aes(label = paste0(round(anxiety_rate, 1), "%\n(n=", n, ")")),
            vjust = -1.2, size = 3.5, fontface = "bold") +
  geom_text(aes(y = ci_lower, label = paste0(round(ci_lower, 1), "%")),
            vjust = 1.5, size = 2.8, color = "gray50") +
  labs(
    title = "√âvolution du taux d'anxi√©t√© avec le temps d'utilisation",
    subtitle = "Courbe avec intervalles de confiance √† 95%",
    x = "Niveau d'utilisation quotidienne",
    y = "Taux d'anxi√©t√© (%)",
    caption = "Barres d'erreur = intervalle de confiance 95%"
  ) +
  ylim(0, max(anxiety_by_usage$ci_upper) * 1.2) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 14),
    axis.text.x = element_text(angle = 45, hjust = 1),
    panel.grid.minor = element_blank()
  )

# Mod√®le de r√©gression
model <- glm(anxiety_binary ~ daily_usage_time_minutes, 
             data = data, family = binomial)

pred_data <- data.frame(
  daily_usage_time_minutes = seq(
    min(data$daily_usage_time_minutes),
    max(data$daily_usage_time_minutes),
    length.out = 100
  )
)

pred_data$predicted_prob <- predict(model, newdata = pred_data, type = "response")

# Graphique 8 (identique √† votre code original)
p8 <- ggplot(data, aes(x = daily_usage_time_minutes, y = anxiety_binary)) +
  geom_point(alpha = 0.3, position = position_jitter(height = 0.02),
             color = "#4E79A7", size = 2) +
  geom_line(data = pred_data, aes(x = daily_usage_time_minutes, y = predicted_prob),
            color = "#E15759", linewidth = 1.5, alpha = 0.8) +
  labs(
    title = "Relation entre temps d'usage et probabilit√© d'anxi√©t√©",
    subtitle = "R√©gression logistique",
    x = "Temps d'utilisation quotidien (minutes)",
    y = "Probabilit√© d'anxi√©t√©"
  ) +
  scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.2),
                     labels = scales::percent_format()) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 14),
    panel.grid.minor = element_blank()
  )

# Afficher les deux graphiques
library(gridExtra)
grid.arrange(p7, p8, ncol = 2)

```


##  √âtape 5 : Mod√©lisation statistique avanc√©e

###  5.1 Analyse par r√©gression logistique multivari√©e
```{webr-r}
#| echo: true
#| warning: false
#| message: false
#| label: logistic-regression

cat("R√âGRESSION LOGISTIQUE MULTIVARI√âE\n")


# Mod√®le complet avec toutes les variables
model_logit <- glm(
  anxiety_binary ~ daily_usage_time_minutes +
    posts_per_day +
    likes_received_per_day +
    comments_received_per_day +
    messages_sent_per_day +
    age +
    gender,
  data = data,
  family = binomial
)

cat("üìä 1. R√âSUM√â COMPLET DU MOD√àLE:\n")
print(summary(model_logit))

# Odds Ratios et intervalles de confiance
cat("\nüéØ 2. ODDS RATIOS (EXPRIM√âS):\n")
odds_ratios <- exp(coef(model_logit))
conf_intervals <- exp(confint(model_logit))

odds_df <- data.frame(
  Variable = names(odds_ratios),
  Odds_Ratio = round(odds_ratios, 3),
  CI_95_lower = round(conf_intervals[, 1], 3),
  CI_95_upper = round(conf_intervals[, 2], 3),
  stringsAsFactors = FALSE
) %>%
  mutate(
    Interpretation = case_when(
      Odds_Ratio > 1 ~ paste0("+", round((Odds_Ratio - 1) * 100, 1), "% de risque"),
      Odds_Ratio < 1 ~ paste0(round((1 - Odds_Ratio) * 100, 1), "% de protection"),
      TRUE ~ "Pas d'effet"
    )
  )

print(odds_df)

# Importance relative des variables
cat("\nüèÜ 3. CLASSEMENT DES VARIABLES PAR IMPORTANCE:\n")
importance_df <- odds_df[-1, ] %>%  # Exclure l'intercept
  arrange(desc(abs(log(Odds_Ratio)))) %>%
  mutate(Rank = row_number())

print(importance_df %>% select(Rank, Variable, Odds_Ratio, Interpretation))

# Performance du mod√®le
cat("\nüìà 4. PERFORMANCE DU MOD√àLE:\n")
null_deviance <- model_logit$null.deviance
residual_deviance <- model_logit$deviance
pseudo_r2 <- 1 - (residual_deviance / null_deviance)

cat("   - D√©viance nulle:", round(null_deviance, 2), "\n")
cat("   - D√©viance r√©siduelle:", round(residual_deviance, 2), "\n")
cat("   - Pseudo R¬≤:", round(pseudo_r2, 3), "\n")
cat("   - AIC:", round(AIC(model_logit), 1), "\n")

# Test de significativit√© globale
cat("\nüîç 5. TEST DE SIGNIFICATIVIT√â GLOBALE:\n")
lr_test <- pchisq(null_deviance - residual_deviance, 
                  df = length(coef(model_logit)) - 1, 
                  lower.tail = FALSE)
cat("   - Test du rapport de vraisemblance: p =", format.pval(lr_test, digits = 3), "\n")

```


### 5.2 Segmentation par clustering
```{webr-r}
#| echo: true
#| warning: false
#| message: false
#| label: clustering-analysis
#| fig-width: 12
#| fig-height: 10


cat("CLUSTERING DES PROFILS D'UTILISATION\n")


# Pr√©paration des donn√©es pour le clustering
cluster_data <- data %>%
  select(
    daily_usage_time_minutes,
    posts_per_day,
    engagement_score,
    age
  ) %>%
  scale()  # Standardisation

# M√©thode du coude pour d√©terminer k optimal
cat("üîç 1. D√âTERMINATION DU NOMBRE OPTIMAL DE CLUSTERS:\n")
wss <- sapply(1:10, function(k) {
  kmeans(cluster_data, centers = k, nstart = 25)$tot.withinss
})

elbow_plot <- data.frame(k = 1:10, wss = wss)
p9 <- ggplot(elbow_plot, aes(x = k, y = wss)) +
  geom_line(color = "steelblue", linewidth = 1) +
  geom_point(color = "steelblue", size = 3) +
  geom_vline(xintercept = 3, linetype = "dashed", color = "red", alpha = 0.5) +
  labs(
    title = "M√©thode du coude pour la s√©lection de k",
    subtitle = "R√©duction marginale de la variance intra-cluster",
    x = "Nombre de clusters (k)",
    y = "Somme des carr√©s intra-cluster"
  ) +
  scale_x_continuous(breaks = 1:10) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

print(p9)

# Application du clustering avec k=3
cat("\nüéØ 2. APPLICATION DU CLUSTERING AVEC k=3:\n")
set.seed(123)
kmeans_result <- kmeans(cluster_data, centers = 3, nstart = 25)
data$cluster <- as.factor(kmeans_result$cluster)

# Profil des clusters
cluster_profile <- data %>%
  group_by(cluster) %>%
  summarise(
    n = n(),
    avg_age = mean(age),
    avg_usage = mean(daily_usage_time_minutes),
    avg_posts = mean(posts_per_day),
    avg_engagement = mean(engagement_score),
    anxiety_rate = mean(anxiety_binary) * 100,
    happiness_rate = mean(positive_emotion) * 100,
    .groups = "drop"
  ) %>%
  mutate(
    size_percent = n / sum(n) * 100,
    cluster_label = paste0("Cluster ", cluster, "\n",
                          round(size_percent, 1), "%\n",
                          "Anxi√©t√©: ", round(anxiety_rate, 1), "%")
  )

cat("üìä PROFILS DES CLUSTERS IDENTIFI√âS:\n")
print(cluster_profile)

# Visualisation des clusters
# Utiliser type = "norm" au lieu du type par d√©faut "t"
p10 <- ggplot(data, aes(x = daily_usage_time_minutes, y = posts_per_day, color = cluster)) +
  geom_point(alpha = 0.6, size = 2.5) +
  stat_ellipse(type = "norm", level = 0.95, linewidth = 1, alpha = 0.3) +
  geom_point(data = cluster_profile, 
             aes(x = avg_usage, y = avg_posts),
             shape = 17, size = 5, color = "black") +
  labs(
    title = "Segmentation des utilisateurs par comportement d'usage",
    subtitle = "Clustering K-means (k=3) bas√© sur l'usage et l'engagement",
    x = "Temps d'utilisation quotidien (minutes)",
    y = "Nombre de posts par jour",
    color = "Cluster",
    caption = "Triangle noir = centre de chaque cluster | Ellipses = 95% de confiance"
  ) +
  scale_color_manual(
    values = c("1" = "#4E79A7", "2" = "#F28E2B", "3" = "#59A14F"),
    labels = setNames(cluster_profile$cluster_label, cluster_profile$cluster)
  ) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 14),
    legend.position = "right",
    legend.text = element_text(size = 9)
  )

print(p10)
```
 

## Conclusion
Cette √©tude d√©montre la puissance des m√©thodes analytiques modernes pour comprendre les relations complexes entre comportements num√©riques et sant√© mentale. L'approche m√©thodologique rigoureuse, combinant statistiques descriptives, mod√©lisation pr√©dictive et segmentation, fournit des insights actionnables pour la pr√©vention et l'intervention.
